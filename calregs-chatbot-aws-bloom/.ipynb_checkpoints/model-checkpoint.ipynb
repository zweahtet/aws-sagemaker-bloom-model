{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76b1217b",
   "metadata": {},
   "source": [
    "## Links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe943b8",
   "metadata": {},
   "source": [
    "- [SageMaker Text Generation Demo](https://github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/jumpstart_text_generation/Amazon_JumpStart_Text_Generation.ipynb)\n",
    "- [SageMaker Sentence Pair Classification Demo](https://github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/jumpstart_sentence_pair_classification/Amazon_JumpStart_Sentence_Pair_Classification.ipynb)\n",
    "- [Fine-tune and host Hugging Face BERT models on Amazon SageMaker](https://aws.amazon.com/blogs/machine-learning/fine-tune-and-host-hugging-face-bert-models-on-amazon-sagemaker/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daf3eb5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a72fabee",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd8e5d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker ipywidgets --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "854e06f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('arn:aws:iam::544669270813:role/service-role/AmazonSageMaker-ExecutionRole-20230307T225001',\n",
       " 'us-east-1',\n",
       " <sagemaker.session.Session at 0x7fef90daf280>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# permissions and environment variables\n",
    "import sagemaker, boto3, json\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "aws_role = get_execution_role()\n",
    "aws_region = boto3.Session().region_name\n",
    "sess = sagemaker.Session()\n",
    "aws_role, aws_region, sess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732b3034",
   "metadata": {},
   "source": [
    "### Select a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e3c4f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"huggingface-spc-bert-base-uncased\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cc797a",
   "metadata": {},
   "source": [
    "[Optional] Select a different JumpStart model. Here, we download jumpstart model_manifest file from the jumpstart s3 bucket, filter-out all the Sentence Pair Classification models and select a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "479d70f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import Dropdown\n",
    "\n",
    "# download JumpStart model_manifest file.\n",
    "boto3.client(\"s3\").download_file(\n",
    "    f\"jumpstart-cache-prod-{aws_region}\", \"models_manifest.json\", \"models_manifest.json\"\n",
    ")\n",
    "with open(\"models_manifest.json\", \"rb\") as json_file:\n",
    "    model_list = json.load(json_file)\n",
    "\n",
    "# filter-out all the Sentence Pair Classification models from the manifest list.\n",
    "spc_models_all_versions, spc_models = [\n",
    "    model[\"model_id\"] for model in model_list if \"-spc-\" in model[\"model_id\"]\n",
    "], []\n",
    "[spc_models.append(model) for model in spc_models_all_versions if model not in spc_models]\n",
    "\n",
    "# display the model-ids in a dropdown to select a model for inference.\n",
    "model_dropdown = Dropdown(\n",
    "    options=spc_models,\n",
    "    value=model_id,\n",
    "    description=\"Select a model\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout={\"width\": \"max-content\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "729ea91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86ded9f4b9284a5e965a0d48ecdfce72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Select a model', index=3, layout=Layout(width='max-content'), options=('huggingface-spc-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# choose model for inference\n",
    "display(model_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1295d789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('huggingface-spc-bert-base-uncased', '*')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_version=\"*\" fetches the latest version of the model\n",
    "model_id, model_version = model_dropdown.value, \"*\"\n",
    "model_id, model_version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf25293",
   "metadata": {},
   "source": [
    "### Run inference on the pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0626e5ac",
   "metadata": {},
   "source": [
    "#### Retreive JumpStart Artifacts & deploy an endpoint\n",
    "\n",
    "This will take a few minutes to fetch the model from sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2cbc1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----!"
     ]
    }
   ],
   "source": [
    "from sagemaker import image_uris, model_uris, script_uris\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "# model_version=\"*\" fetches the latest version of the model.\n",
    "infer_model_id, infer_model_version = model_dropdown.value, \"*\"\n",
    "\n",
    "endpoint_name = name_from_base(f\"jumpstart-example-{infer_model_id}\")\n",
    "\n",
    "inference_instance_type = \"ml.m5.xlarge\"\n",
    "\n",
    "# Retrieve the inference docker container uri.\n",
    "deploy_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,\n",
    "    image_scope=\"inference\",\n",
    "    model_id=infer_model_id,\n",
    "    model_version=infer_model_version,\n",
    "    instance_type=inference_instance_type,\n",
    ")\n",
    "# Retrieve the inference script uri.\n",
    "deploy_source_uri = script_uris.retrieve(\n",
    "    model_id=infer_model_id, model_version=infer_model_version, script_scope=\"inference\"\n",
    ")\n",
    "# Retrieve the base model uri.\n",
    "base_model_uri = model_uris.retrieve(\n",
    "    model_id=infer_model_id, model_version=infer_model_version, model_scope=\"inference\"\n",
    ")\n",
    "# Create the SageMaker model instance. Note that we need to pass Predictor class when we deploy model through Model class,\n",
    "# for being able to run inference through the SageMaker API.\n",
    "model = Model(\n",
    "    image_uri=deploy_image_uri,\n",
    "    source_dir=deploy_source_uri,\n",
    "    model_data=base_model_uri,\n",
    "    entry_point=\"inference.py\",\n",
    "    role=aws_role,\n",
    "    predictor_cls=Predictor,\n",
    "    name=endpoint_name,\n",
    ")\n",
    "# deploy the Model.\n",
    "base_model_predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=inference_instance_type,\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fd904f",
   "metadata": {},
   "source": [
    "#### Example input sentences for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0b6a076",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_pair1 = [\n",
    "    \"How many octaves does Beyonce have?\",\n",
    "    \"Beyoncé's vocal range spans four octaves.\",\n",
    "]\n",
    "sentence_pair2 = [\n",
    "    \"How many octaves does Beyonce have?\",\n",
    "    \"While another critic says she is a \"\n",
    "    \"Vocal acrobat, being able to sing long and complex melismas and vocal runs effortlessly, and in key.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6629658",
   "metadata": {},
   "source": [
    "#### Query endpoint and parse response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "054ae23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference:\n",
      "Input text: '['How many octaves does Beyonce have?', \"Beyoncé's vocal range spans four octaves.\"]'\n",
      "Model prediction: [2.8040263652801514, -3.48968768119812]\n",
      "Labels: ['entail', 'no_entail']\n",
      "Predicted Label: \u001b[1mentail\u001b[0m\n",
      "\n",
      "Inference:\n",
      "Input text: '['How many octaves does Beyonce have?', 'While another critic says she is a Vocal acrobat, being able to sing long and complex melismas and vocal runs effortlessly, and in key.']'\n",
      "Model prediction: [-2.672070264816284, 3.6076502799987793]\n",
      "Labels: ['entail', 'no_entail']\n",
      "Predicted Label: \u001b[1mno_entail\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newline, bold, unbold = \"\\n\", \"\\033[1m\", \"\\033[0m\"\n",
    "\n",
    "def query_endpoint(encoded_text):\n",
    "    response = base_model_predictor.predict(\n",
    "        encoded_text, {\"ContentType\": \"application/list-text\", \"Accept\": \"application/json;verbose\"}\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "def parse_response(query_response):\n",
    "    model_predictions = json.loads(query_response)\n",
    "    probabilities, labels, predicted_label = (\n",
    "        model_predictions[\"probabilities\"],\n",
    "        model_predictions[\"labels\"],\n",
    "        model_predictions[\"predicted_label\"],\n",
    "    )\n",
    "    return probabilities, labels, predicted_label\n",
    "\n",
    "\n",
    "for sentence_pair in [sentence_pair1, sentence_pair2]:\n",
    "    query_response = query_endpoint(json.dumps(sentence_pair).encode(\"utf-8\"))\n",
    "    probabilities, labels, predicted_label = parse_response(query_response)\n",
    "    print(\n",
    "        f\"Inference:{newline}\"\n",
    "        f\"Input text: '{sentence_pair}'{newline}\"\n",
    "        f\"Model prediction: {probabilities}{newline}\"\n",
    "        f\"Labels: {labels}{newline}\"\n",
    "        f\"Predicted Label: {bold}{predicted_label}{unbold}{newline}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f931ac",
   "metadata": {},
   "source": [
    "#### Clean up the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "586dd939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the SageMaker endpoint and the attached resources\n",
    "base_model_predictor.delete_model()\n",
    "base_model_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b870984",
   "metadata": {},
   "source": [
    "### Finetune the pre-trained model on a custom dataset\n",
    "\n",
    "Previously, we saw how to run inference on a pre-trained model, which was fine-tuned on QNLI dataset. Next, we discuss how a model can be finetuned to a custom dataset.\n",
    "\n",
    "The Text Embedding model can be fine-tuned on any sentence pair classification dataset in the same way the model available for inference has been fine-tuned on the QNLI dataset. The model available for fine-tuning attaches a binary classification layer to the Text Embedding model and initializes the layer parameters to random values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c949d5",
   "metadata": {},
   "source": [
    "#### Retrieve Jumpstart Training artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ef72a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris, model_uris, script_uris, hyperparameters\n",
    "\n",
    "model_id, model_version = model_dropdown.value, \"*\"\n",
    "training_instance_type = \"ml.p3.2xlarge\"\n",
    "\n",
    "# Retrieve the docker image\n",
    "train_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    image_scope=\"training\",\n",
    "    instance_type=training_instance_type,\n",
    ")\n",
    "# Retrieve the training script\n",
    "train_source_uri = script_uris.retrieve(\n",
    "    model_id=model_id, model_version=model_version, script_scope=\"training\"\n",
    ")\n",
    "# Retrieve the pre-trained model tarball to further fine-tune\n",
    "train_model_uri = model_uris.retrieve(\n",
    "    model_id=model_id, model_version=model_version, model_scope=\"training\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7edf44",
   "metadata": {},
   "source": [
    "#### Set Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cb3c8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample training data is available in this bucket\n",
    "training_data_bucket = f\"jumpstart-cache-prod-{aws_region}\"\n",
    "# For a quick demonstration of training we have created a random subset of QNLI dataset.\n",
    "# For complete QNLI dataset replace \"QNLI-tiny\" with \"QNLI\" in the line below.\n",
    "training_data_prefix = \"training-datasets/QNLI-tiny/\"\n",
    "\n",
    "training_dataset_s3_path = f\"s3://{training_data_bucket}/{training_data_prefix}\"\n",
    "\n",
    "output_bucket = sess.default_bucket()\n",
    "output_prefix = \"jumpstart-example-spc-training\"\n",
    "\n",
    "s3_output_location = f\"s3://{output_bucket}/{output_prefix}/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9228ee67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': '3', 'adam-learning-rate': '2e-05', 'batch-size': '64', 'reinitialize-top-layer': 'Auto', 'train-only-top-layer': 'False'}\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import hyperparameters\n",
    "\n",
    "# Retrieve the default hyper-parameters for fine-tuning the model\n",
    "hyperparameters = hyperparameters.retrieve_default(model_id=model_id, model_version=model_version)\n",
    "\n",
    "# [Optional] Override default hyperparameters with custom values\n",
    "hyperparameters[\"batch-size\"] = \"64\"\n",
    "print(hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df37a6d3",
   "metadata": {},
   "source": [
    "#### Train with Automatic Model Tuning\n",
    "Amazon SageMaker automatic model tuning, also known as hyperparameter tuning, finds the best version of a model by running many training jobs on your dataset using the algorithm and ranges of hyperparameters that you specify. It then chooses the hyperparameter values that result in a model that performs the best, as measured by a metric that you choose. We will use a HyperparameterTuner object to interact with Amazon SageMaker hyperparameter tuning APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b5c4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import ContinuousParameter\n",
    "\n",
    "# Use AMT for tuning and selecting the best model\n",
    "use_amt = True\n",
    "\n",
    "# Define objective metric per framework, based on which the best model will be selected.\n",
    "metric_definitions_per_model = {\n",
    "    \"tensorflow\": {\n",
    "        \"metrics\": [{\"Name\": \"val_accuracy\", \"Regex\": \"val_accuracy: ([0-9\\\\.]+)\"}],\n",
    "        \"type\": \"Maximize\",\n",
    "    },\n",
    "    \"huggingface\": {\n",
    "        \"metrics\": [{\"Name\": \"eval_accuracy\", \"Regex\": \"'eval_accuracy': ([0-9\\\\.]+)\"}],\n",
    "        \"type\": \"Maximize\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# You can select from the hyperparameters supported by the model, and configure ranges of values to be searched for training the optimal model.(https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-ranges.html)\n",
    "hyperparameter_ranges = {\n",
    "    \"adam-learning-rate\": ContinuousParameter(0.000001, 0.001, scaling_type=\"Logarithmic\")\n",
    "}\n",
    "\n",
    "# Increase the total number of training jobs run by AMT, for increased accuracy (and training time).\n",
    "max_jobs = 6\n",
    "# Change parallel training jobs run by AMT to reduce total training time, constrained by your account limits.\n",
    "# if max_jobs=max_parallel_jobs then Bayesian search turns to Random.\n",
    "max_parallel_jobs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f61be28",
   "metadata": {},
   "source": [
    "#### Start Training\n",
    "We start by creating the estimator object with all the required assets and then launch the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290ea96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.tuner import HyperparameterTuner\n",
    "\n",
    "training_job_name = name_from_base(f\"jumpstart-example-{model_id}-transfer-learning\")\n",
    "\n",
    "# Create SageMaker Estimator instance\n",
    "spc_estimator = Estimator(\n",
    "    role=aws_role,\n",
    "    image_uri=train_image_uri,\n",
    "    source_dir=train_source_uri,\n",
    "    model_uri=train_model_uri,\n",
    "    entry_point=\"transfer_learning.py\",\n",
    "    instance_count=1,\n",
    "    instance_type=training_instance_type,\n",
    "    max_run=360000,\n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path=s3_output_location,\n",
    "    base_job_name=training_job_name,\n",
    ")\n",
    "\n",
    "if use_amt:\n",
    "    metric_definitions = next(\n",
    "        value for key, value in metric_definitions_per_model.items() if model_id.startswith(key)\n",
    "    )\n",
    "\n",
    "    hp_tuner = HyperparameterTuner(\n",
    "        spc_estimator,\n",
    "        metric_definitions[\"metrics\"][0][\"Name\"],\n",
    "        hyperparameter_ranges,\n",
    "        metric_definitions[\"metrics\"],\n",
    "        max_jobs=max_jobs,\n",
    "        max_parallel_jobs=max_parallel_jobs,\n",
    "        objective_type=metric_definitions[\"type\"],\n",
    "        base_tuning_job_name=training_job_name,\n",
    "    )\n",
    "\n",
    "    # Launch a SageMaker Tuning job to search for the best hyperparameters\n",
    "    hp_tuner.fit({\"training\": training_dataset_s3_path})\n",
    "else:\n",
    "    # Launch a SageMaker Training job by passing s3 path of the training data\n",
    "    spc_estimator.fit({\"training\": training_dataset_s3_path}, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca77eeef",
   "metadata": {},
   "source": [
    "#### Deploy & run inference on the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d83c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_instance_type = \"ml.m5.xlarge\"\n",
    "\n",
    "# Retrieve the inference docker container uri\n",
    "deploy_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,\n",
    "    image_scope=\"inference\",\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    instance_type=inference_instance_type,\n",
    ")\n",
    "# Retrieve the inference script uri\n",
    "deploy_source_uri = script_uris.retrieve(\n",
    "    model_id=model_id, model_version=model_version, script_scope=\"inference\"\n",
    ")\n",
    "\n",
    "endpoint_name = name_from_base(f\"jumpstart-example-FT-{model_id}-\")\n",
    "\n",
    "# Use the estimator from the previous step to deploy to a SageMaker endpoint\n",
    "finetuned_predictor = (hp_tuner if use_amt else spc_estimator).deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=inference_instance_type,\n",
    "    entry_point=\"inference.py\",\n",
    "    image_uri=deploy_image_uri,\n",
    "    source_dir=deploy_source_uri,\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2557350f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_pair1 = [\n",
    "    \"How many octaves does Beyonce have?\",\n",
    "    \"Beyoncé's vocal range spans four octaves.\",\n",
    "]\n",
    "sentence_pair2 = [\n",
    "    \"How many octaves does Beyonce have?\",\n",
    "    \"While another critic says she is a \"\n",
    "    \"Vocal acrobat, being able to sing long and complex melismas and vocal runs effortlessly, and in key.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dbe161",
   "metadata": {},
   "source": [
    "Next, we query the finetuned model, parse the response and print the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee79b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "newline, bold, unbold = \"\\n\", \"\\033[1m\", \"\\033[0m\"\n",
    "\n",
    "\n",
    "def query_endpoint(encoded_text):\n",
    "    response = finetuned_predictor.predict(\n",
    "        encoded_text, {\"ContentType\": \"application/list-text\", \"Accept\": \"application/json;verbose\"}\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "def parse_response(query_response):\n",
    "    model_predictions = json.loads(query_response)\n",
    "    probabilities, labels, predicted_label = (\n",
    "        model_predictions[\"probabilities\"],\n",
    "        model_predictions[\"labels\"],\n",
    "        model_predictions[\"predicted_label\"],\n",
    "    )\n",
    "    return probabilities, labels, predicted_label\n",
    "\n",
    "\n",
    "for sentence_pair in [sentence_pair1, sentence_pair2]:\n",
    "    query_response = query_endpoint(json.dumps(sentence_pair).encode(\"utf-8\"))\n",
    "    probabilities, labels, predicted_label = parse_response(query_response)\n",
    "    print(\n",
    "        f\"Inference:{newline}\"\n",
    "        f\"Input text: '{sentence_pair}'{newline}\"\n",
    "        f\"Model prediction: {probabilities}{newline}\"\n",
    "        f\"Labels: {labels}{newline}\"\n",
    "        f\"Predicted Label: {bold}{predicted_label}{unbold}{newline}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2227fbbe",
   "metadata": {},
   "source": [
    "#### Next, we clean up the deployed endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a4ee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the SageMaker endpoint and the attached resources\n",
    "finetuned_predictor.delete_model()\n",
    "finetuned_predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
